# processing/docker-compose.yml
version: '3.8'

services:
  # Spark Master for Processing
  spark-master-processing:
    image: bitnami/spark:3.4.1
    container_name: processing-spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8082:8080"  # Different port to avoid conflict
      - "7078:7077"  # Different port to avoid conflict
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./config:/opt/spark-config
      - ./utils:/opt/spark-utils
      - ../storage/data:/opt/data
    networks:
      - processing-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Spark Worker for Processing
  spark-worker-processing:
    image: bitnami/spark:3.4.1
    container_name: processing-spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master-processing:7077
      - SPARK_WORKER_MEMORY=3G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      spark-master-processing:
        condition: service_healthy
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./config:/opt/spark-config
      - ./utils:/opt/spark-utils
      - ../storage/data:/opt/data
    networks:
      - processing-network

  # Processing Job Runner
  processing-job-runner:
    build: .
    container_name: processing-job-runner
    environment:
      - SPARK_MASTER_URL=spark://spark-master-processing:7077
      - MINIO_ENDPOINT=http://minio:9000
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
    volumes:
      - ./spark-apps:/app/spark-apps
      - ./config:/app/config
      - ./utils:/app/utils
      - ../logs:/app/logs
    depends_on:
      - spark-master-processing
    networks:
      - processing-network
      - ecommerce-network  # Connect to main network
    command: ["python", "/app/spark-apps/bronze_ingestion.py", "--mode", "batch", "--source", "all", "--date", "2024-06-07"]

networks:
  processing-network:
    driver: bridge
  ecommerce-network:
    external: true