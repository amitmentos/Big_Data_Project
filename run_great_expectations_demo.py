#!/usr/bin/env python3
# run_great_expectations_demo.py

"""
Great Expectations Integration Demo for E-commerce Data Platform

This script demonstrates the new Great Expectations integration alongside
the existing custom data quality framework.

Usage:
    python3 run_great_expectations_demo.py
"""

import os
import sys
import time
import logging
from datetime import datetime, timedelta

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def main():
    """Run Great Expectations integration demo"""
    
    print("ğŸš€ Great Expectations Integration Demo")
    print("=" * 60)
    print()
    
    # Check if platform is running
    print("ğŸ” Checking platform status...")
    platform_status = os.system("docker-compose ps --services --filter 'status=running' | wc -l")
    
    if platform_status != 0:
        print("âŒ Platform services not detected. Please start the platform first:")
        print("   ./start_platform_demo.sh")
        return 1
    
    print("âœ… Platform services are running")
    print()
    
    # Demo sections
    demo_sections = [
        {
            'title': 'ğŸ“‹ Great Expectations Configuration',
            'description': 'Showing the Great Expectations setup for medallion architecture',
            'action': show_ge_configuration
        },
        {
            'title': 'ğŸ” Expectation Suites Overview',
            'description': 'Reviewing expectation suites for bronze, silver, and gold layers',
            'action': show_expectation_suites
        },
        {
            'title': 'âš¡ Running Validation Demo',
            'description': 'Demonstrating validation with sample data',
            'action': run_validation_demo
        },
        {
            'title': 'ğŸ”„ Hybrid Framework Demo',
            'description': 'Showing combined Great Expectations + Custom validation',
            'action': run_hybrid_demo
        },
        {
            'title': 'ğŸ“Š Validation Report',
            'description': 'Generating comprehensive validation reports',
            'action': show_validation_reports
        }
    ]
    
    # Run demo sections
    for i, section in enumerate(demo_sections, 1):
        print(f"{section['title']}")
        print(f"   {section['description']}")
        print()
        
        try:
            section['action']()
        except Exception as e:
            print(f"âŒ Error in demo section: {str(e)}")
            logger.error(f"Demo section failed: {str(e)}")
        
        if i < len(demo_sections):
            print("\n" + "â”€" * 60 + "\n")
    
    print("ğŸ‰ Great Expectations Integration Demo Complete!")
    print()
    print("Next Steps:")
    print("â€¢ Review the generated data quality reports")
    print("â€¢ Customize expectation suites for your specific needs")
    print("â€¢ Integrate with your CI/CD pipeline")
    print("â€¢ Set up automated alerting based on validation results")
    
    return 0

def show_ge_configuration():
    """Show Great Expectations configuration"""
    
    print("ğŸ“‹ Great Expectations Configuration Structure:")
    print()
    
    # Show directory structure
    if os.path.exists("processing/great_expectations"):
        os.system("tree processing/great_expectations/ 2>/dev/null || find processing/great_expectations/ -type f | head -20")
    else:
        print("âŒ Great Expectations configuration not found")
        return
    
    print()
    print("ğŸ“Š Data Sources Configured:")
    print("   â€¢ Bronze Layer: Raw data validation (schema, format, basic quality)")
    print("   â€¢ Silver Layer: Standardized data validation (transformations, enrichments)")  
    print("   â€¢ Gold Layer: Business metrics validation (aggregations, calculations)")
    
    print()
    print("ğŸ—ï¸  Architecture Integration:")
    print("   â€¢ S3/MinIO data source connections")
    print("   â€¢ Spark execution engine for big data")
    print("   â€¢ Iceberg table format support")
    print("   â€¢ Medallion architecture patterns")

def show_expectation_suites():
    """Show expectation suites overview"""
    
    print("ğŸ” Expectation Suites Overview:")
    print()
    
    expectation_files = [
        ("Bronze Raw User Events", "processing/great_expectations/expectations/bronze_raw_user_events.json"),
        ("Silver Standardized Events", "processing/great_expectations/expectations/silver_standardized_user_events.json"),
        ("Gold Fact Sales", "processing/great_expectations/expectations/gold_fact_sales.json")
    ]
    
    for suite_name, file_path in expectation_files:
        print(f"ğŸ“‹ {suite_name}:")
        
        if os.path.exists(file_path):
            # Count expectations
            try:
                import json
                with open(file_path, 'r') as f:
                    suite_data = json.load(f)
                    expectations = suite_data.get('expectations', [])
                    print(f"   â””â”€ {len(expectations)} expectations defined")
                    
                    # Show expectation types
                    exp_types = set()
                    for exp in expectations[:5]:  # Show first 5
                        exp_type = exp.get('expectation_type', '').replace('expect_', '').replace('_', ' ')
                        exp_types.add(exp_type)
                        
                    for exp_type in sorted(exp_types):
                        print(f"      â€¢ {exp_type}")
                        
                    if len(expectations) > 5:
                        print(f"      â€¢ ... and {len(expectations) - 5} more")
                        
            except Exception as e:
                print(f"   â””â”€ Error reading expectations: {str(e)}")
        else:
            print("   â””â”€ âŒ Suite file not found")
        
        print()

def run_validation_demo():
    """Run validation demo"""
    
    print("âš¡ Running Great Expectations Validation Demo:")
    print()
    
    # Use today's date for demo
    demo_date = datetime.now().strftime('%Y-%m-%d')
    
    print(f"ğŸ“… Demo Date: {demo_date}")
    print()
    
    # Check if we're running in Docker environment
    in_docker = os.path.exists("/.dockerenv")
    
    # Validate bronze layer
    print("ğŸ¥‰ Validating Bronze Layer...")
    
    if in_docker:
        # Running inside container - use direct python call
        bronze_cmd = f"""
        cd /opt/processing/spark-apps && \
        python3 great_expectations_validator.py \
        --layer bronze \
        --date {demo_date} \
        --context-dir /opt/processing/great_expectations \
        --output-format text
        """
    else:
        # Running on host - use docker exec to run in Spark container
        docker_compose_cmd = "docker compose" if os.system("docker compose version > /dev/null 2>&1") == 0 else "docker-compose"
        bronze_cmd = f"""
        {docker_compose_cmd} exec -T spark-master /opt/bitnami/spark/bin/spark-submit \
        --master spark://spark-master:7077 \
        --py-files /opt/processing/utils \
        /opt/processing/spark-apps/great_expectations_validator.py \
        --layer bronze \
        --date {demo_date} \
        --context-dir /opt/processing/great_expectations \
        --output-format text
        """
    
    print("   Running bronze validation...")
    result = os.system(bronze_cmd)
    
    if result == 0:
        print("   âœ… Bronze validation completed successfully")
    else:
        print("   âš ï¸  Bronze validation completed with issues")
    
    print()
    
    # Show that we can also validate individual tables
    print("ğŸ” Individual Table Validation Example:")
    if in_docker:
        print("   Command: python3 great_expectations_validator.py --layer silver --table standardized_user_events --date 2024-12-15")
    else:
        print("   Command: docker compose exec spark-master spark-submit /opt/processing/spark-apps/great_expectations_validator.py --layer silver --table standardized_user_events --date 2024-12-15")
    print()

def run_hybrid_demo():
    """Run hybrid framework demo"""
    
    print("ğŸ”„ Hybrid Framework Demo (Great Expectations + Custom):")
    print()
    
    demo_date = datetime.now().strftime('%Y-%m-%d')
    
    print("This demonstrates running both validation frameworks together:")
    print()
    print("ğŸ“Š Great Expectations provides:")
    print("   â€¢ Industry-standard data quality expectations")
    print("   â€¢ Schema validation and statistical profiling")
    print("   â€¢ Data documentation and lineage")
    print("   â€¢ Automated data quality reporting")
    print()
    print("ğŸ—ï¸  Custom Framework provides:")
    print("   â€¢ Business-specific validation rules")
    print("   â€¢ Complex cross-table validations")  
    print("   â€¢ Real-time data quality metrics")
    print("   â€¢ Custom alerting and monitoring")
    print()
    
    # Show hybrid command example
    print("ğŸ”§ Hybrid Validation Command Example:")
    print(f"   python3 hybrid_data_quality_validator.py --layer gold --date {demo_date}")
    print()
    
    print("ğŸ“ˆ Benefits of Hybrid Approach:")
    print("   â€¢ Comprehensive coverage of all data quality aspects")
    print("   â€¢ Best-of-breed tooling for different scenarios")
    print("   â€¢ Flexibility to use either framework independently")
    print("   â€¢ Unified reporting and monitoring")

def show_validation_reports():
    """Show validation report examples"""
    
    print("ğŸ“Š Validation Report Examples:")
    print()
    
    # Show sample report structure
    print("ğŸ¯ Comprehensive Validation Report Structure:")
    print("""
================================================================================
COMPREHENSIVE DATA QUALITY VALIDATION REPORT
================================================================================
Timestamp: 2024-12-15T10:30:00
Layer: gold
Process Date: 2024-12-15

ğŸ¯ OVERALL STATUS: PASSED
ğŸ“Š SUCCESS RATE: 94.2%

ğŸ“ˆ SUMMARY STATISTICS:
   Tables Validated: 3
   âœ… Passed: 2
   âš ï¸  Warnings: 1
   âŒ Failed: 0
   ğŸ” Total Checks: 45
   âœ… Checks Passed: 42
   âŒ Checks Failed: 3

ğŸ”§ VALIDATION FRAMEWORKS:
   ğŸ“‹ Great Expectations: âœ… Enabled
   ğŸ—ï¸  Custom Framework: âœ… Enabled

ğŸ“‹ TABLE DETAILS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… fact_sales: PASSED
   â””â”€ Great Expectations: PASSED
   â””â”€ Custom Framework: PASSED
   â””â”€ Checks: 18/20 passed (90.0%)

âš ï¸  customer_product_interactions: WARNING
   â””â”€ Great Expectations: WARNING
   â””â”€ Custom Framework: PASSED
   â””â”€ Checks: 14/15 passed (93.3%)

ğŸ’¡ RECOMMENDATIONS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ âœ… Excellent data quality (94.2% success rate). Consider this as benchmark.
â€¢ ğŸ” Address null values in column 'product_rating'
â€¢ âš ï¸  1 tables have warnings. Schedule review during next maintenance window.

================================================================================
    """)
    
    print("ğŸ“‹ Available Report Formats:")
    print("   â€¢ Text format: Human-readable console output")
    print("   â€¢ JSON format: Machine-readable for integration")
    print("   â€¢ HTML format: Rich web-based reports (via Great Expectations)")
    print()
    
    print("ğŸ”” Alerting Integration:")
    print("   â€¢ Email notifications for critical failures")
    print("   â€¢ Slack alerts for warnings")
    print("   â€¢ PagerDuty integration for urgent issues")
    print("   â€¢ Custom webhook support for other systems")

if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Demo interrupted by user")
        sys.exit(0)
    except Exception as e:
        print(f"\n\nâŒ Demo failed: {str(e)}")
        logger.error(f"Demo failed: {str(e)}")
        sys.exit(1) 